{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d919300a",
   "metadata": {},
   "source": [
    "# üß† Choix du Mod√®le et Justifications\n",
    "\n",
    "## 1. üéØ Objectif du syst√®me\n",
    "\n",
    "L'objectif de ce projet est de concevoir un **syst√®me de recommandation de contenu** capable de g√©n√©rer des suggestions personnalis√©es de vid√©os √† partir des **profils utilisateurs** et des **caract√©ristiques des vid√©os**. Une attention particuli√®re est port√©e √† la gestion des **cold users** (utilisateurs sans historique d'interaction).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ‚öôÔ∏è Type de mod√®le choisi : **Content-Based Filtering**\n",
    "\n",
    "J'ai opt√© pour une approche **content-based** car elle pr√©sente plusieurs avantages dans notre contexte :\n",
    "\n",
    "- **Ind√©pendance par rapport aux autres utilisateurs** : utile lorsque l‚Äôhistorique est partiel ou inexistant.\n",
    "- **Exploitation directe des caract√©ristiques vid√©os** : via des vecteurs de contenu normalis√©s.\n",
    "- **Simplicit√© de d√©ploiement** : le mod√®le peut fonctionner avec de nouvelles vid√©os sans n√©cessiter de retrain.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. üë• Gestion des cold users via **R√©seau Social**\n",
    "\n",
    "Un des points critiques est la recommandation pour les **utilisateurs sans profil (cold start)**. Pour cela, j'ai introduit une **propagation de profils via le graphe social**, selon cette logique :\n",
    "\n",
    "- Si un utilisateur n‚Äôa pas de donn√©es d‚Äôinteractions, on r√©cup√®re les profils de ses **amis directs** (et indirects jusqu'√† une profondeur `d`).\n",
    "- Ces profils sont **pond√©r√©s** par un facteur de d√©croissance exponentielle `1 / coef_decay^depth`, refl√©tant l‚Äôinfluence d√©croissante des amis lointains.\n",
    "- Cela permet de **reconstruire un profil estim√© coh√©rent** √† partir du comportement de la communaut√©.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "734a706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /lre/home/cderuelle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /lre/home/cderuelle/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import ast\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def cosine_similarity_vec(a, B):\n",
    "    \"\"\"\n",
    "    Calcule la similarit√© cosinus entre un vecteur a (1D) et une matrice B (2D),\n",
    "    retourne un vecteur des similarit√©s (a vs chaque ligne de B).\n",
    "    Utilise scikit-learn pour la coh√©rence.\n",
    "    \"\"\"\n",
    "    # Reshape a en matrice 2D (n√©cessaire pour scikit-learn)\n",
    "    a_reshaped = a.reshape(1, -1)\n",
    "    # Utiliser la fonction scikit-learn\n",
    "    sim = cosine_similarity(a_reshaped, B).flatten()\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9dd98",
   "metadata": {},
   "source": [
    "# Script : `run_optimized_recommender`\n",
    "\n",
    "Ce script impl√©mente un syst√®me de recommandation **content-based** (bas√© sur le contenu des vid√©os) avec gestion des utilisateurs froids (**cold users**) √† l‚Äôaide d‚Äôun **r√©seau social**. Il permet de g√©n√©rer des profils utilisateurs optimis√©s et de les sauvegarder pour un usage ult√©rieur.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Cr√©er des **profils utilisateurs** √† partir de leurs interactions vid√©o (watch ratio) et, pour ceux sans interactions (cold users), estimer leur profil √† partir de ceux de leurs amis (propagation dans le r√©seau social).\n",
    "\n",
    "## √âtapes principales\n",
    "\n",
    "### 1. Chargement des donn√©es\n",
    "- Lecture des vid√©os et du r√©seau social.\n",
    "- Chargement en batch de la `big_matrix` contenant les interactions utilisateurs.\n",
    "\n",
    "### 2. Traitement des vid√©os\n",
    "- Chaque vid√©o poss√®de un vecteur de caract√©ristiques.\n",
    "- Cr√©ation d‚Äôune matrice `item_features`.\n",
    "\n",
    "### 3. Cr√©ation des profils utilisateurs\n",
    "- Pour chaque utilisateur, on construit un vecteur de profil bas√© sur les vid√©os regard√©es pond√©r√©es par leur **watch ratio**\n",
    "- Si `watch_ratio` > 0, le profil est pond√©r√© plus fortement (avec un carr√© : `** 2`).\n",
    "\n",
    "### 4. Gestion des **cold users**\n",
    "- Pour les utilisateurs sans interaction :\n",
    "  - Propagation de l‚Äôinformation via leurs amis directs et indirects (jusqu‚Äô√† `max_depth`).\n",
    "  - Chaque niveau a une **influence d√©croissante** (par `coef_decay`).\n",
    "  - Si aucun ami utile, on leur affecte un **profil moyen global**.\n",
    "\n",
    "### 5. Sauvegarde du mod√®le\n",
    "- Le mod√®le est sauv√© via `pickle` et contient :\n",
    "  - Les caract√©ristiques des vid√©os.\n",
    "  - Les profils utilisateurs (froids + actifs).\n",
    "  - Les mappings `video_id ‚Üî index`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84948ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chargement des m√©tadonn√©es...\n",
      "2. Pr√©paration des caract√©ristiques de contenu...\n",
      "3. Chargement et traitement des interactions (big_matrix) par lots...\n",
      "Traitement du lot 1 (500 lignes)...\n",
      "Traitement du lot 2 (500 lignes)...\n",
      "Traitement du lot 3 (500 lignes)...\n",
      "Traitement du lot 4 (500 lignes)...\n",
      "Traitement du lot 5 (500 lignes)...\n",
      "Traitement du lot 6 (500 lignes)...\n",
      "Traitement du lot 7 (500 lignes)...\n",
      "Traitement du lot 8 (500 lignes)...\n",
      "Traitement du lot 9 (500 lignes)...\n",
      "Traitement du lot 10 (500 lignes)...\n",
      "Traitement du lot 11 (500 lignes)...\n",
      "Traitement du lot 12 (500 lignes)...\n",
      "Traitement du lot 13 (500 lignes)...\n",
      "Traitement du lot 14 (500 lignes)...\n",
      "Traitement du lot 15 (500 lignes)...\n",
      "Traitement du lot 16 (500 lignes)...\n",
      "Traitement du lot 17 (500 lignes)...\n",
      "Traitement du lot 18 (500 lignes)...\n",
      "Traitement du lot 19 (500 lignes)...\n",
      "Traitement du lot 20 (500 lignes)...\n",
      "Traitement du lot 21 (500 lignes)...\n",
      "Traitement du lot 22 (500 lignes)...\n",
      "Traitement du lot 23 (500 lignes)...\n",
      "Traitement du lot 24 (500 lignes)...\n",
      "Traitement du lot 25 (500 lignes)...\n",
      "Traitement du lot 26 (500 lignes)...\n",
      "Traitement du lot 27 (500 lignes)...\n",
      "Traitement du lot 28 (500 lignes)...\n",
      "Traitement du lot 29 (500 lignes)...\n",
      "Traitement du lot 30 (500 lignes)...\n",
      "Traitement du lot 31 (500 lignes)...\n",
      "Traitement du lot 32 (500 lignes)...\n",
      "Traitement du lot 33 (500 lignes)...\n",
      "Traitement du lot 34 (500 lignes)...\n",
      "Traitement du lot 35 (500 lignes)...\n",
      "Traitement du lot 36 (500 lignes)...\n",
      "Traitement du lot 37 (500 lignes)...\n",
      "Traitement du lot 38 (500 lignes)...\n",
      "Traitement du lot 39 (500 lignes)...\n",
      "Traitement du lot 40 (500 lignes)...\n",
      "Traitement du lot 41 (500 lignes)...\n",
      "Traitement du lot 42 (500 lignes)...\n",
      "Traitement du lot 43 (500 lignes)...\n",
      "Traitement du lot 44 (500 lignes)...\n",
      "Traitement du lot 45 (500 lignes)...\n",
      "Traitement du lot 46 (500 lignes)...\n",
      "Traitement du lot 47 (500 lignes)...\n",
      "Traitement du lot 48 (500 lignes)...\n",
      "Traitement du lot 49 (500 lignes)...\n",
      "Traitement du lot 50 (500 lignes)...\n",
      "Traitement du lot 51 (500 lignes)...\n",
      "Traitement du lot 52 (500 lignes)...\n",
      "Traitement du lot 53 (500 lignes)...\n",
      "Traitement du lot 54 (500 lignes)...\n",
      "Traitement du lot 55 (500 lignes)...\n",
      "Traitement du lot 56 (500 lignes)...\n",
      "Traitement du lot 57 (500 lignes)...\n",
      "Traitement du lot 58 (500 lignes)...\n",
      "Traitement du lot 59 (500 lignes)...\n",
      "Traitement du lot 60 (500 lignes)...\n",
      "Traitement du lot 61 (500 lignes)...\n",
      "Traitement du lot 62 (500 lignes)...\n",
      "Traitement du lot 63 (500 lignes)...\n",
      "Traitement du lot 64 (500 lignes)...\n",
      "Traitement du lot 65 (500 lignes)...\n",
      "Traitement du lot 66 (500 lignes)...\n",
      "Traitement du lot 67 (500 lignes)...\n",
      "Traitement du lot 68 (500 lignes)...\n",
      "Traitement du lot 69 (500 lignes)...\n",
      "Traitement du lot 70 (500 lignes)...\n",
      "Traitement du lot 71 (500 lignes)...\n",
      "Traitement du lot 72 (500 lignes)...\n",
      "Traitement du lot 73 (500 lignes)...\n",
      "Traitement du lot 74 (500 lignes)...\n",
      "Traitement du lot 75 (500 lignes)...\n",
      "Traitement du lot 76 (500 lignes)...\n",
      "Traitement du lot 77 (500 lignes)...\n",
      "Traitement du lot 78 (500 lignes)...\n",
      "Traitement du lot 79 (500 lignes)...\n",
      "Traitement du lot 80 (500 lignes)...\n",
      "Traitement du lot 81 (500 lignes)...\n",
      "Traitement du lot 82 (500 lignes)...\n",
      "Traitement du lot 83 (500 lignes)...\n",
      "Traitement du lot 84 (500 lignes)...\n",
      "Traitement du lot 85 (500 lignes)...\n",
      "Traitement du lot 86 (500 lignes)...\n",
      "Traitement du lot 87 (500 lignes)...\n",
      "Traitement du lot 88 (500 lignes)...\n",
      "Traitement du lot 89 (500 lignes)...\n",
      "Traitement du lot 90 (500 lignes)...\n",
      "Traitement du lot 91 (500 lignes)...\n",
      "Traitement du lot 92 (500 lignes)...\n",
      "Traitement du lot 93 (500 lignes)...\n",
      "Traitement du lot 94 (500 lignes)...\n",
      "Traitement du lot 95 (500 lignes)...\n",
      "Traitement du lot 96 (500 lignes)...\n",
      "Traitement du lot 97 (500 lignes)...\n",
      "Traitement du lot 98 (500 lignes)...\n",
      "Traitement du lot 99 (500 lignes)...\n",
      "Traitement du lot 100 (500 lignes)...\n",
      "Traitement du lot 101 (500 lignes)...\n",
      "Traitement du lot 102 (500 lignes)...\n",
      "Traitement du lot 103 (500 lignes)...\n",
      "Traitement du lot 104 (500 lignes)...\n",
      "Traitement du lot 105 (500 lignes)...\n",
      "Traitement du lot 106 (500 lignes)...\n",
      "Traitement du lot 107 (500 lignes)...\n",
      "Traitement du lot 108 (500 lignes)...\n",
      "Traitement du lot 109 (500 lignes)...\n",
      "Traitement du lot 110 (500 lignes)...\n",
      "Traitement du lot 111 (500 lignes)...\n",
      "Traitement du lot 112 (500 lignes)...\n",
      "Traitement du lot 113 (500 lignes)...\n",
      "Traitement du lot 114 (500 lignes)...\n",
      "Traitement du lot 115 (500 lignes)...\n",
      "Traitement du lot 116 (500 lignes)...\n",
      "Traitement du lot 117 (500 lignes)...\n",
      "Traitement du lot 118 (500 lignes)...\n",
      "Traitement du lot 119 (500 lignes)...\n",
      "Traitement du lot 120 (500 lignes)...\n",
      "Traitement du lot 121 (500 lignes)...\n",
      "Traitement du lot 122 (500 lignes)...\n",
      "Traitement du lot 123 (500 lignes)...\n",
      "Traitement du lot 124 (500 lignes)...\n",
      "Traitement du lot 125 (500 lignes)...\n",
      "Traitement du lot 126 (500 lignes)...\n",
      "Traitement du lot 127 (500 lignes)...\n",
      "Traitement du lot 128 (500 lignes)...\n",
      "Traitement du lot 129 (500 lignes)...\n",
      "Traitement du lot 130 (500 lignes)...\n",
      "Traitement du lot 131 (500 lignes)...\n",
      "Traitement du lot 132 (500 lignes)...\n",
      "Traitement du lot 133 (500 lignes)...\n",
      "Traitement du lot 134 (500 lignes)...\n",
      "Traitement du lot 135 (500 lignes)...\n",
      "Traitement du lot 136 (500 lignes)...\n",
      "Traitement du lot 137 (500 lignes)...\n",
      "Traitement du lot 138 (500 lignes)...\n",
      "Traitement du lot 139 (500 lignes)...\n",
      "Traitement du lot 140 (500 lignes)...\n",
      "Traitement du lot 141 (500 lignes)...\n",
      "Traitement du lot 142 (500 lignes)...\n",
      "Traitement du lot 143 (500 lignes)...\n",
      "Traitement du lot 144 (500 lignes)...\n",
      "Traitement du lot 145 (500 lignes)...\n",
      "Traitement du lot 146 (500 lignes)...\n",
      "Traitement du lot 147 (500 lignes)...\n",
      "Traitement du lot 148 (500 lignes)...\n",
      "Traitement du lot 149 (500 lignes)...\n",
      "Traitement du lot 150 (500 lignes)...\n",
      "Traitement du lot 151 (500 lignes)...\n",
      "Traitement du lot 152 (500 lignes)...\n",
      "Traitement du lot 153 (500 lignes)...\n",
      "Traitement du lot 154 (500 lignes)...\n",
      "Traitement du lot 155 (500 lignes)...\n",
      "Traitement du lot 156 (500 lignes)...\n",
      "Traitement du lot 157 (500 lignes)...\n",
      "Traitement du lot 158 (500 lignes)...\n",
      "Traitement du lot 159 (500 lignes)...\n",
      "Traitement du lot 160 (500 lignes)...\n",
      "Traitement du lot 161 (500 lignes)...\n",
      "Traitement du lot 162 (500 lignes)...\n",
      "Traitement du lot 163 (500 lignes)...\n",
      "Traitement du lot 164 (500 lignes)...\n",
      "Traitement du lot 165 (500 lignes)...\n",
      "Traitement du lot 166 (500 lignes)...\n",
      "Traitement du lot 167 (500 lignes)...\n",
      "Traitement du lot 168 (500 lignes)...\n",
      "Traitement du lot 169 (500 lignes)...\n",
      "Traitement du lot 170 (500 lignes)...\n",
      "Traitement du lot 171 (500 lignes)...\n",
      "Traitement du lot 172 (500 lignes)...\n",
      "Traitement du lot 173 (500 lignes)...\n",
      "Traitement du lot 174 (500 lignes)...\n",
      "Traitement du lot 175 (500 lignes)...\n",
      "Traitement du lot 176 (500 lignes)...\n",
      "Traitement du lot 177 (500 lignes)...\n",
      "Traitement du lot 178 (500 lignes)...\n",
      "Traitement du lot 179 (500 lignes)...\n",
      "Traitement du lot 180 (500 lignes)...\n",
      "Traitement du lot 181 (500 lignes)...\n",
      "Traitement du lot 182 (500 lignes)...\n",
      "Traitement du lot 183 (500 lignes)...\n",
      "Traitement du lot 184 (500 lignes)...\n",
      "Traitement du lot 185 (500 lignes)...\n",
      "Traitement du lot 186 (500 lignes)...\n",
      "Traitement du lot 187 (500 lignes)...\n",
      "Traitement du lot 188 (500 lignes)...\n",
      "Traitement du lot 189 (500 lignes)...\n",
      "Traitement du lot 190 (500 lignes)...\n",
      "Traitement du lot 191 (500 lignes)...\n",
      "Traitement du lot 192 (500 lignes)...\n",
      "Traitement du lot 193 (500 lignes)...\n",
      "Traitement du lot 194 (500 lignes)...\n",
      "Traitement du lot 195 (500 lignes)...\n",
      "Traitement du lot 196 (500 lignes)...\n",
      "Traitement du lot 197 (500 lignes)...\n",
      "Traitement du lot 198 (500 lignes)...\n",
      "Traitement du lot 199 (500 lignes)...\n",
      "Traitement du lot 200 (500 lignes)...\n",
      "Traitement du lot 201 (500 lignes)...\n",
      "Traitement du lot 202 (500 lignes)...\n",
      "Traitement du lot 203 (500 lignes)...\n",
      "Traitement du lot 204 (500 lignes)...\n",
      "Traitement du lot 205 (500 lignes)...\n",
      "Traitement du lot 206 (500 lignes)...\n",
      "Traitement du lot 207 (500 lignes)...\n",
      "Traitement du lot 208 (500 lignes)...\n",
      "Traitement du lot 209 (500 lignes)...\n",
      "Traitement du lot 210 (500 lignes)...\n",
      "Traitement du lot 211 (500 lignes)...\n",
      "Traitement du lot 212 (500 lignes)...\n",
      "Traitement du lot 213 (500 lignes)...\n",
      "Traitement du lot 214 (500 lignes)...\n",
      "Traitement du lot 215 (500 lignes)...\n",
      "Traitement du lot 216 (500 lignes)...\n",
      "Traitement du lot 217 (500 lignes)...\n",
      "Traitement du lot 218 (500 lignes)...\n",
      "Traitement du lot 219 (500 lignes)...\n",
      "Traitement du lot 220 (500 lignes)...\n",
      "Traitement du lot 221 (500 lignes)...\n",
      "Traitement du lot 222 (500 lignes)...\n",
      "Traitement du lot 223 (500 lignes)...\n",
      "Traitement du lot 224 (500 lignes)...\n",
      "Traitement du lot 225 (500 lignes)...\n",
      "Traitement du lot 226 (500 lignes)...\n",
      "Traitement du lot 227 (500 lignes)...\n",
      "Traitement du lot 228 (500 lignes)...\n",
      "Traitement du lot 229 (500 lignes)...\n",
      "Traitement du lot 230 (500 lignes)...\n",
      "Traitement du lot 231 (500 lignes)...\n",
      "Traitement du lot 232 (500 lignes)...\n",
      "Traitement du lot 233 (500 lignes)...\n",
      "Traitement du lot 234 (500 lignes)...\n",
      "Traitement du lot 235 (500 lignes)...\n",
      "Traitement du lot 236 (500 lignes)...\n",
      "Traitement du lot 237 (500 lignes)...\n",
      "Traitement du lot 238 (500 lignes)...\n",
      "Traitement du lot 239 (500 lignes)...\n",
      "Traitement du lot 240 (500 lignes)...\n",
      "Traitement du lot 241 (500 lignes)...\n",
      "Traitement du lot 242 (500 lignes)...\n",
      "Traitement du lot 243 (500 lignes)...\n",
      "Traitement du lot 244 (500 lignes)...\n",
      "Traitement du lot 245 (500 lignes)...\n",
      "Traitement du lot 246 (500 lignes)...\n",
      "Traitement du lot 247 (500 lignes)...\n",
      "Traitement du lot 248 (500 lignes)...\n",
      "Traitement du lot 249 (500 lignes)...\n",
      "Traitement du lot 250 (500 lignes)...\n",
      "Traitement du lot 251 (500 lignes)...\n",
      "Traitement du lot 252 (500 lignes)...\n",
      "Traitement du lot 253 (500 lignes)...\n",
      "Traitement du lot 254 (500 lignes)...\n",
      "Traitement du lot 255 (500 lignes)...\n",
      "Traitement du lot 256 (500 lignes)...\n",
      "Traitement du lot 257 (500 lignes)...\n",
      "Traitement du lot 258 (500 lignes)...\n",
      "Traitement du lot 259 (500 lignes)...\n",
      "Traitement du lot 260 (500 lignes)...\n",
      "Traitement du lot 261 (500 lignes)...\n",
      "Traitement du lot 262 (500 lignes)...\n",
      "Traitement du lot 263 (500 lignes)...\n",
      "Traitement du lot 264 (500 lignes)...\n",
      "Traitement du lot 265 (500 lignes)...\n",
      "Traitement du lot 266 (500 lignes)...\n",
      "Traitement du lot 267 (500 lignes)...\n",
      "Traitement du lot 268 (500 lignes)...\n",
      "Traitement du lot 269 (500 lignes)...\n",
      "Traitement du lot 270 (500 lignes)...\n",
      "Traitement du lot 271 (500 lignes)...\n",
      "Traitement du lot 272 (500 lignes)...\n",
      "Traitement du lot 273 (500 lignes)...\n",
      "Traitement du lot 274 (500 lignes)...\n",
      "Traitement du lot 275 (500 lignes)...\n",
      "Traitement du lot 276 (500 lignes)...\n",
      "Traitement du lot 277 (500 lignes)...\n",
      "Traitement du lot 278 (500 lignes)...\n",
      "Traitement du lot 279 (500 lignes)...\n",
      "Traitement du lot 280 (500 lignes)...\n",
      "Traitement du lot 281 (500 lignes)...\n",
      "Traitement du lot 282 (500 lignes)...\n",
      "Traitement du lot 283 (500 lignes)...\n",
      "Traitement du lot 284 (500 lignes)...\n",
      "Traitement du lot 285 (500 lignes)...\n",
      "Traitement du lot 286 (500 lignes)...\n",
      "Traitement du lot 287 (500 lignes)...\n",
      "Traitement du lot 288 (500 lignes)...\n",
      "Traitement du lot 289 (500 lignes)...\n",
      "Traitement du lot 290 (500 lignes)...\n",
      "Traitement du lot 291 (500 lignes)...\n",
      "Traitement du lot 292 (500 lignes)...\n",
      "Traitement du lot 293 (500 lignes)...\n",
      "Traitement du lot 294 (500 lignes)...\n",
      "Traitement du lot 295 (500 lignes)...\n",
      "Traitement du lot 296 (500 lignes)...\n",
      "Traitement du lot 297 (500 lignes)...\n",
      "Traitement du lot 298 (500 lignes)...\n",
      "Traitement du lot 299 (500 lignes)...\n",
      "Traitement du lot 300 (500 lignes)...\n",
      "Traitement du lot 301 (500 lignes)...\n",
      "Traitement du lot 302 (500 lignes)...\n",
      "Traitement du lot 303 (500 lignes)...\n",
      "Traitement du lot 304 (500 lignes)...\n",
      "Traitement du lot 305 (500 lignes)...\n",
      "Traitement du lot 306 (500 lignes)...\n",
      "Traitement du lot 307 (500 lignes)...\n",
      "Traitement du lot 308 (500 lignes)...\n",
      "Traitement du lot 309 (500 lignes)...\n",
      "Traitement du lot 310 (500 lignes)...\n",
      "Traitement du lot 311 (500 lignes)...\n",
      "Traitement du lot 312 (500 lignes)...\n",
      "Traitement du lot 313 (500 lignes)...\n",
      "Traitement du lot 314 (500 lignes)...\n",
      "Traitement du lot 315 (500 lignes)...\n",
      "Traitement du lot 316 (500 lignes)...\n",
      "Traitement du lot 317 (500 lignes)...\n",
      "Traitement du lot 318 (500 lignes)...\n",
      "Traitement du lot 319 (500 lignes)...\n",
      "Traitement du lot 320 (500 lignes)...\n",
      "Traitement du lot 321 (500 lignes)...\n",
      "Traitement du lot 322 (500 lignes)...\n",
      "Traitement du lot 323 (500 lignes)...\n",
      "Traitement du lot 324 (500 lignes)...\n",
      "Traitement du lot 325 (500 lignes)...\n",
      "Traitement du lot 326 (500 lignes)...\n",
      "Traitement du lot 327 (500 lignes)...\n",
      "Traitement du lot 328 (500 lignes)...\n",
      "Traitement du lot 329 (500 lignes)...\n",
      "Traitement du lot 330 (500 lignes)...\n",
      "Traitement du lot 331 (500 lignes)...\n",
      "Traitement du lot 332 (500 lignes)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2593388/772382505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m run_optimized_recommender(\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mbig_matrix_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KuaiRec 2.0/data/big_matrix.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mitem_categories_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KuaiRec 2.0/data/item_categories.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2593388/772382505.py\u001b[0m in \u001b[0;36mrun_optimized_recommender\u001b[0;34m(big_matrix_path, item_categories_path, social_network_path, save_path, max_users, batch_size, max_depth, coef_decay)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4. Construction des profils pour cold users √† partir du r√©seau social...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import ast  # pour convertir les listes string en listes Python\n",
    "from collections import deque\n",
    "\n",
    "def run_optimized_recommender(big_matrix_path, item_categories_path, social_network_path, \n",
    "                             save_path='models/content_recommender.pkl', max_users=None, batch_size=1000,\n",
    "                             max_depth=3, coef_decay=2.0):\n",
    "    \"\"\"\n",
    "    Ex√©cute le syst√®me de recommandation content-based optimis√© avec int√©gration des profils cold users via r√©seau social.\n",
    "    \n",
    "    Args:\n",
    "        max_depth: profondeur max pour propagation amis (1 = amis directs)\n",
    "        coef_decay: facteur de d√©croissance des coefficients (exponentiel)\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    print(\"1. Chargement des m√©tadonn√©es...\")\n",
    "    item_categories = pd.read_csv(item_categories_path)\n",
    "    social_network = pd.read_csv(social_network_path)\n",
    "    \n",
    "    print(\"2. Pr√©paration des caract√©ristiques de contenu...\")\n",
    "    max_len = 100  # taille max des vecteurs\n",
    "    def pad_vector(v):\n",
    "        v = ast.literal_eval(v)\n",
    "        if len(v) > max_len:\n",
    "            return v[:max_len]\n",
    "        else:\n",
    "            return v + [0]*(max_len - len(v))\n",
    "\n",
    "    item_features = item_categories['feat'].apply(pad_vector).tolist()\n",
    "    item_features = np.array(item_features)\n",
    "\n",
    "    # Mappings video_id <-> index\n",
    "    video_indices = {vid: idx for idx, vid in enumerate(item_categories['video_id'])}\n",
    "    video_id_to_index = {idx: vid for vid, idx in video_indices.items()}\n",
    "    \n",
    "    print(\"3. Chargement et traitement des interactions (big_matrix) par lots...\")\n",
    "    \n",
    "    user_profiles = {}\n",
    "    users_processed = set()\n",
    "    total_processed = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(pd.read_csv(big_matrix_path, chunksize=batch_size)):\n",
    "        print(f\"Traitement du lot {chunk_idx+1} ({len(chunk)} lignes)...\")\n",
    "        \n",
    "        if 'watch_ratio' not in chunk.columns:\n",
    "            chunk['watch_ratio'] = (chunk['play_duration'] / chunk['video_duration']).clip(0,1)\n",
    "        \n",
    "        for user_id, user_data in chunk.groupby('user_id'):\n",
    "            if user_id in users_processed:\n",
    "                continue\n",
    "            \n",
    "            user_profile = np.zeros(item_features.shape[1])\n",
    "            video_count = 0\n",
    "            \n",
    "            for _, row in user_data.iterrows():\n",
    "                vid = row['video_id']\n",
    "                watch_ratio = row['watch_ratio']\n",
    "                if vid in video_indices:\n",
    "                    vid_idx = video_indices[vid]\n",
    "                    video_feat = item_features[vid_idx]\n",
    "                    # Correction op√©rateur ^ => ** pour puissance\n",
    "                    user_profile += video_feat * (watch_ratio ** 2)\n",
    "                    video_count += 1\n",
    "            \n",
    "            if video_count > 0:\n",
    "                user_profile /= video_count\n",
    "                user_profiles[user_id] = user_profile\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            users_processed.add(user_id)\n",
    "            total_processed += 1\n",
    "            \n",
    "            if total_processed % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = total_processed / elapsed\n",
    "                remaining = ((max_users or total_processed) - total_processed) / rate if rate > 0 else 0\n",
    "                print(f\"Progression: {total_processed} utilisateurs trait√©s\")\n",
    "                print(f\"Temps √©coul√©: {elapsed/60:.2f} min, Temps restant estim√©: {remaining/60:.2f} min\")\n",
    "            \n",
    "            if max_users and total_processed >= max_users:\n",
    "                break\n",
    "        \n",
    "        if max_users and total_processed >= max_users:\n",
    "            break\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    print(\"4. Construction des profils pour cold users √† partir du r√©seau social...\")\n",
    "\n",
    "    # Convertir friend_list de string √† liste Python\n",
    "    social_network['friend_list'] = social_network['friend_list'].apply(ast.literal_eval)\n",
    "    social_dict = dict(zip(social_network['user_id'], social_network['friend_list']))\n",
    "\n",
    "    # Profil moyen global pour fallback\n",
    "    all_profiles = np.array(list(user_profiles.values()))\n",
    "    mean_profile = np.mean(all_profiles, axis=0)\n",
    "\n",
    "    # Tous les utilisateurs pr√©sents dans big_matrix\n",
    "    # Tous les utilisateurs pr√©sents dans le dataset de test (small_matrix)\n",
    "    all_user_ids = set(pd.read_csv('KuaiRec 2.0/data/small_matrix.csv')['user_id'].unique())\n",
    "    cold_users = all_user_ids - set(user_profiles.keys())\n",
    "\n",
    "\n",
    "    print(f\"Nombre de cold users d√©tect√©s: {len(cold_users)}\")\n",
    "\n",
    "    # Calcul des coefficients de pond√©ration d√©croissants\n",
    "    coefficients = [1 / (coef_decay ** i) for i in range(max_depth)]\n",
    "\n",
    "    from collections import deque\n",
    "\n",
    "    def get_influenced_profile(user_id):\n",
    "        visited = set([user_id])\n",
    "        queue = deque([(user_id, 0)])  # (user_id, profondeur)\n",
    "        agg_profile = None\n",
    "        total_weight = 0\n",
    "\n",
    "        while queue:\n",
    "            current_user, depth = queue.popleft()\n",
    "            if depth > 0 and current_user in user_profiles:\n",
    "                weight = coefficients[depth - 1]\n",
    "                if agg_profile is None:\n",
    "                    agg_profile = weight * user_profiles[current_user]\n",
    "                else:\n",
    "                    agg_profile += weight * user_profiles[current_user]\n",
    "                total_weight += weight\n",
    "            \n",
    "            if depth < max_depth:\n",
    "                friends = social_dict.get(current_user, [])\n",
    "                for f in friends:\n",
    "                    if f not in visited:\n",
    "                        visited.add(f)\n",
    "                        queue.append((f, depth + 1))\n",
    "        if agg_profile is not None:\n",
    "            return agg_profile / total_weight\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Estimer profil cold users par propagation dans r√©seau social\n",
    "    for cold_user in cold_users:\n",
    "        profile = get_influenced_profile(cold_user)\n",
    "        if profile is not None:\n",
    "            user_profiles[cold_user] = profile\n",
    "        else:\n",
    "            user_profiles[cold_user] = mean_profile\n",
    "\n",
    "    print(f\"Profils pour cold users cr√©√©s avec propagation √† profondeur {max_depth}.\")\n",
    "\n",
    "    print(f\"5. Sauvegarde des profils de {len(user_profiles)} utilisateurs...\")\n",
    "    \n",
    "    model_data = {\n",
    "        'item_features': item_features,\n",
    "        'user_profiles': user_profiles,\n",
    "        'video_indices': video_indices,\n",
    "        'video_id_to_index': video_id_to_index\n",
    "    }\n",
    "    \n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    \n",
    "    print(f\"Mod√®le sauvegard√© dans {save_path}\")\n",
    "    print(f\"Temps total d'ex√©cution: {(time.time() - start_time)/60:.2f} minutes\")\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "\n",
    "run_optimized_recommender(\n",
    "    big_matrix_path='KuaiRec 2.0/data/big_matrix.csv',\n",
    "    item_categories_path='KuaiRec 2.0/data/item_categories.csv',\n",
    "    social_network_path='KuaiRec 2.0/data/social_network.csv',\n",
    "    save_path='models/content_recommender.pkl',\n",
    "    max_users=10000,\n",
    "    batch_size=500,\n",
    "    max_depth=5,     # tu peux changer la profondeur max ici\n",
    "    coef_decay=5   # tu peux changer la vitesse de d√©croissance des coefficients\n",
    ")\n",
    "\n",
    "print(\"Recommandation optimis√©e termin√©e.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375ffd4",
   "metadata": {},
   "source": [
    "# Fonctions d‚Äô√©valuation des recommandations\n",
    "\n",
    "Ces trois fonctions permettent de mesurer la qualit√© des recommandations faites par un syst√®me.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 1. `calculate_precision_at_k(...)`\n",
    "\n",
    "### Objectif :\n",
    "Mesurer **la proportion d‚Äô√©l√©ments recommand√©s parmi les `k` premiers qui sont pertinents**.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∏ 2. `calculate_recall_at_k(...)`\n",
    "\n",
    "### Objectif :\n",
    "Mesurer **la proportion de vid√©os pertinentes qui ont √©t√© retrouv√©es dans les `k` recommandations**.\n",
    "\n",
    "---\n",
    "\n",
    "## üî∑ 3. `calculate_ndcg_at_k(...)`\n",
    "\n",
    "### Objectif :\n",
    "Mesurer **la qualit√© de l‚Äôordre des recommandations**, en tenant compte de leur pertinence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0f7f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calcule la pr√©cision@k (proportion d'items recommand√©s qui sont pertinents)\n",
    "    \"\"\"\n",
    "    if len(recommended_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Limiter √† k recommandations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    # Compter les items pertinents parmi les recommandations\n",
    "    relevant_count = len(set(recommended_k) & set(relevant_items))\n",
    "    \n",
    "    return relevant_count / min(k, len(recommended_k))\n",
    "\n",
    "def calculate_recall_at_k(recommended_items, relevant_items, k=10):\n",
    "    \"\"\"\n",
    "    Calcule le rappel@k (proportion d'items pertinents qui ont √©t√© recommand√©s)\n",
    "    \"\"\"\n",
    "    if len(relevant_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Limiter √† k recommandations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    # Compter les items pertinents parmi les recommandations\n",
    "    relevant_count = len(set(recommended_k) & set(relevant_items))\n",
    "    \n",
    "    return relevant_count / len(relevant_items)\n",
    "\n",
    "def calculate_ndcg_at_k(recommended_items, relevant_items_with_ratings, k=10):\n",
    "    \"\"\"\n",
    "    Calcule le NDCG@k (Normalized Discounted Cumulative Gain)\n",
    "    \n",
    "    Args:\n",
    "        recommended_items: Liste des items recommand√©s\n",
    "        relevant_items_with_ratings: Dictionnaire {item_id: rating}\n",
    "        k: Nombre de recommandations √† consid√©rer\n",
    "    \"\"\"\n",
    "    if len(recommended_items) == 0 or len(relevant_items_with_ratings) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Limiter √† k recommandations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    # Calculer le DCG (Discounted Cumulative Gain)\n",
    "    dcg = 0.0\n",
    "    for i, item_id in enumerate(recommended_k):\n",
    "        if item_id in relevant_items_with_ratings:\n",
    "            # Position i+1 car les indices commencent √† 0\n",
    "            # La formule log2(i+2) commence √† la position 1 (log2(2)=1)\n",
    "            dcg += (2 ** relevant_items_with_ratings[item_id] - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # Calculer le DCG id√©al\n",
    "    # Trier les ratings par ordre d√©croissant\n",
    "    sorted_ratings = sorted(relevant_items_with_ratings.values(), reverse=True)\n",
    "    idcg = 0.0\n",
    "    for i, rating in enumerate(sorted_ratings[:k]):\n",
    "        idcg += (2 ** rating - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # √âviter la division par z√©ro\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dcg / idcg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342626c",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "\n",
    "- Charger un mod√®le de recommandation √† partir d‚Äôun fichier.\n",
    "- Calculer la **similarit√©** entre le profil de l'utilisateur et les vid√©os disponibles.\n",
    "- Retourner les vid√©os les plus proches du profil utilisateur (recommand√©es).\n",
    "\n",
    "## √âtapes d√©taill√©es\n",
    "\n",
    "1. **Chargement du mod√®le** :\n",
    "   - Le fichier contient :\n",
    "     - `item_features` : vecteurs d√©crivant les vid√©os.\n",
    "     - `user_profiles` : vecteurs d√©crivant les utilisateurs.\n",
    "     - `video_id_to_index` : correspondance entre les vid√©os et leurs indices.\n",
    "\n",
    "2. **V√©rification** : si l‚Äôutilisateur n‚Äôa pas de profil, la fonction retourne une liste vide (`[]`).\n",
    "\n",
    "3. **Calcul de similarit√©** :\n",
    "   - Utilise une fonction externe `cosine_similarity_vec(user_profile, item_features)` pour comparer le profil utilisateur √† tous les profils vid√©o.\n",
    "\n",
    "4. **Tri des r√©sultats** :\n",
    "   - Trie les vid√©os par similarit√© d√©croissante (les plus proches en premier).\n",
    "\n",
    "5. **Construction de la liste finale** :\n",
    "   - R√©cup√®re les identifiants des vid√©os les plus proches.\n",
    "   - S‚Äôarr√™te une fois `n_recommendations` vid√©os s√©lectionn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a8879ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_recommend(model_path, user_id, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Charge un mod√®le et g√©n√®re des recommandations pour un utilisateur\n",
    "    \"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    item_features = model_data['item_features']\n",
    "    user_profiles = model_data['user_profiles']\n",
    "    video_indices = model_data['video_indices']\n",
    "    video_id_to_index = model_data['video_id_to_index']\n",
    "    \n",
    "    if user_id not in user_profiles:\n",
    "        return []\n",
    "    \n",
    "    user_profile = user_profiles[user_id]\n",
    "    \n",
    "    # Calculer la similarit√©\n",
    "    user_profile = user_profiles[user_id]  # shape (features,)\n",
    "    similarities = cosine_similarity_vec(user_profile, item_features)\n",
    "\n",
    "    \n",
    "    # Trier par similarit√©\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Convertir les indices en video_ids\n",
    "    recommendations = []\n",
    "    video_id_list = list(video_id_to_index.keys())\n",
    "    \n",
    "    for idx in sorted_indices:\n",
    "        if idx < len(video_id_list):\n",
    "            video_id = video_id_list[idx]\n",
    "            recommendations.append(video_id)\n",
    "            if len(recommendations) >= n_recommendations:\n",
    "                break\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f6f4",
   "metadata": {},
   "source": [
    "## üî∏ √âtapes du programme\n",
    "\n",
    "1. **Chargement des fichiers** :\n",
    "   - Le mod√®le sauvegard√© (`.pkl`) contient les profils utilisateurs et les caract√©ristiques des vid√©os.\n",
    "   - Les interactions utilisateurs (avec leur `watch_ratio`) sont dans un fichier CSV.\n",
    "   - Le r√©seau social (qui sont les amis de qui) est aussi charg√©.\n",
    "\n",
    "2. **Boucle sur chaque utilisateur** :\n",
    "   - Si l'utilisateur a regard√© des vid√©os (watch_ratio > 0.5), on utilise cela comme \"v√©rit√© terrain\".\n",
    "   - Si l'utilisateur **n'a pas de donn√©es** (cas cold-start), on utilise la moyenne des profils de ses amis pour faire des recommandations.\n",
    "   - S‚Äôil n‚Äôa **aucun ami actif**, il est ignor√©.\n",
    "\n",
    "3. **Calcul des m√©triques** pour chaque utilisateur et pour plusieurs valeurs de `k` (1, 10, 20, 50, 100).\n",
    "\n",
    "4. **Affichage final** : pour chaque `k`, le programme affiche la **moyenne de la pr√©cision, du rappel et du NDCG** sur tous les utilisateurs √©valu√©s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f075111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- R√©sultats pour k = 1 ---\n",
      "Precision@1: 0.5379\n",
      "Recall@1:    0.0002\n",
      "NDCG@1:      0.0058\n",
      "\n",
      "--- R√©sultats pour k = 10 ---\n",
      "Precision@10: 0.5422\n",
      "Recall@10:    0.0022\n",
      "NDCG@10:      0.0115\n",
      "\n",
      "--- R√©sultats pour k = 20 ---\n",
      "Precision@20: 0.5381\n",
      "Recall@20:    0.0045\n",
      "NDCG@20:      0.0143\n",
      "\n",
      "--- R√©sultats pour k = 50 ---\n",
      "Precision@50: 0.4898\n",
      "Recall@50:    0.0101\n",
      "NDCG@50:      0.0201\n",
      "\n",
      "--- R√©sultats pour k = 100 ---\n",
      "Precision@100: 0.4463\n",
      "Recall@100:    0.0185\n",
      "NDCG@100:      0.0255\n"
     ]
    }
   ],
   "source": [
    "def evaluate_all_users(model_path, test_data_path, social_network_path):\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Param√®tres\n",
    "    ks = [1, 10, 20, 50, 100]\n",
    "\n",
    "    # Charger le mod√®le\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "\n",
    "    # Charger les donn√©es de test et social network\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    social_network = pd.read_csv(social_network_path)\n",
    "    social_network['friend_list'] = social_network['friend_list'].apply(eval)  # convertit les listes en objets Python\n",
    "\n",
    "    user_ids = test_data['user_id'].unique()\n",
    "    user_profiles = model_data['user_profiles']\n",
    "\n",
    "    # M√©triques\n",
    "    metrics = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in ks}\n",
    "    evaluated_users = 0\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        recommendations = load_and_recommend(model_path, user_id, n_recommendations=max(ks))\n",
    "        user_test_data = test_data[test_data['user_id'] == user_id]\n",
    "        relevant_items = user_test_data[user_test_data['watch_ratio'] > 0.5]['video_id'].tolist()\n",
    "\n",
    "        # Si utilisateur cold (pas d'items pertinents)\n",
    "        if not relevant_items:\n",
    "            # Tenter profil ami\n",
    "            friends = social_network[social_network['user_id'] == user_id]['friend_list']\n",
    "            if friends.empty:\n",
    "                continue  # pas d'amis -> pas d'√©valuation possible\n",
    "            friends = friends.values[0]\n",
    "            friend_profiles = [user_profiles[f] for f in friends if f in user_profiles]\n",
    "            if not friend_profiles:\n",
    "                continue  # amis sans profil\n",
    "            avg_friend_profile = np.mean(friend_profiles, axis=0)\n",
    "            # Recommandations bas√©es sur profil ami\n",
    "            recommendations = recommend_from_profile(avg_friend_profile, model_data, n_recommendations=max(ks))\n",
    "\n",
    "        if not recommendations:\n",
    "            continue\n",
    "\n",
    "        relevant_items_with_ratings = dict(zip(user_test_data['video_id'].tolist(), user_test_data['watch_ratio'].tolist()))\n",
    "\n",
    "        for k in ks:\n",
    "            top_k_recs = recommendations[:k]\n",
    "            precision = calculate_precision_at_k(top_k_recs, relevant_items, k)\n",
    "            recall = calculate_recall_at_k(top_k_recs, relevant_items, k)\n",
    "            ndcg = calculate_ndcg_at_k(top_k_recs, relevant_items_with_ratings, k)\n",
    "\n",
    "            metrics[k]['precision'].append(precision)\n",
    "            metrics[k]['recall'].append(recall)\n",
    "            metrics[k]['ndcg'].append(ndcg)\n",
    "\n",
    "        evaluated_users += 1\n",
    "\n",
    "    if evaluated_users == 0:\n",
    "        print(\"Aucun utilisateur valide pour l'√©valuation.\")\n",
    "        return\n",
    "\n",
    "    for k in ks:\n",
    "        print(f\"\\n--- R√©sultats pour k = {k} ---\")\n",
    "        print(f\"Precision@{k}: {sum(metrics[k]['precision']) / evaluated_users:.4f}\")\n",
    "        print(f\"Recall@{k}:    {sum(metrics[k]['recall']) / evaluated_users:.4f}\")\n",
    "        print(f\"NDCG@{k}:      {sum(metrics[k]['ndcg']) / evaluated_users:.4f}\")\n",
    "\n",
    "\n",
    "def recommend_from_profile(user_profile, model_data, n_recommendations=10):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    item_features = model_data['item_features']\n",
    "    video_id_to_index = model_data['video_id_to_index']\n",
    "    user_profile = user_profile.reshape(1, -1)\n",
    "\n",
    "    similarities = cosine_similarity(user_profile, item_features).flatten()\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    recommendations = []\n",
    "    for idx in sorted_indices:\n",
    "        vid = video_id_to_index.get(idx)\n",
    "        if vid is not None:\n",
    "            recommendations.append(vid)\n",
    "            if len(recommendations) >= n_recommendations:\n",
    "                break\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# Exemple d‚Äôappel\n",
    "evaluate_all_users(\n",
    "    model_path='models/content_recommender.pkl',\n",
    "    test_data_path='KuaiRec 2.0/data/small_matrix.csv',\n",
    "    social_network_path='KuaiRec 2.0/data/social_network.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c676c508",
   "metadata": {},
   "source": [
    "### 1. Precision@k\n",
    "La pr√©cision est relativement √©lev√©e √† tous les niveaux de *k* :\n",
    "\n",
    "- Par exemple, **Precision@1 = 0.6010**, ce qui signifie que dans **60.1% des cas**, l‚Äô√©l√©ment en premi√®re position est pertinent.\n",
    "- Cependant, la pr√©cision diminue l√©g√®rement avec l‚Äôaugmentation de *k*, ce qui est attendu \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Recall@k\n",
    "Le **recall** est extr√™mement faible :\n",
    "\n",
    "- **Recall@1 = 0.0003**, **Recall@100 = 0.0188**.\n",
    "- Cela signifie que le syst√®me retrouve **moins de 2% des √©l√©ments pertinents** dans les 100 recommandations.\n",
    "- C‚Äôest un **signe alarmant** que le syst√®me **rate massivement** les items pertinents, **malgr√© une bonne pr√©cision apparente**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. NDCG@k\n",
    "Le **NDCG (Normalized Discounted Cumulative Gain)** reste tr√®s bas :\n",
    "\n",
    "- **NDCG@1 = 0.0086**, **NDCG@100 = 0.0257**.\n",
    "- Cela indique que **l‚Äôordre des recommandations ne refl√®te pas bien la pertinence des items**.\n",
    "- M√™me les quelques items pertinents retrouv√©s sont **souvent mal class√©s**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162f98c",
   "metadata": {},
   "source": [
    "## Tentatives d'am√©lioration des performances\n",
    "\n",
    "Malgr√© mes efforts et plusieurs tentatives pour am√©liorer les performances du syst√®me de recommandation ‚Äî en particulier les m√©triques **NDCG** et **Recall** ‚Äî je n'ai pas r√©ussi √† obtenir de r√©sultats significativement meilleurs que ceux pr√©sent√©s.\n",
    "\n",
    "### Ce que j'ai essay√© :\n",
    "- Ajustement du nombre de recommandations (`k`) pour observer l‚Äôimpact sur les r√©sultats.\n",
    "- Utilisation du profil moyen des amis pour les utilisateurs \"cold-start\".\n",
    "- Modification des hyperparametres."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
